# One Piece Wiki Scraper – Cursor Coding Rules

## General
- Implement the entire project in a **single Python file** inside `src/` folder.
- Have a separate `requirements.txt` file with only the dependencies needed.
- No tests, no demo code, no logging.
- Code must be **simple, readable, and minimal**.
- Follow **PEP 8** style.
- Use clear variable names and concise docstrings.

## Functionality
1. **Articles List**
   - A hard-coded Python list with the article names from One Piece Wiki.

2. **Fetching Data**
   - Use the **MediaWiki API** from `https://onepiece.fandom.com/api.php` to fetch the article content, tables, and image URLs.
   - Ensure that section order is preserved.

3. **Folder & File Structure**
   - Create a folder named exactly as the article (with slugified safe characters for file system).
   - Each **top-level section** should be a `.txt` file inside that folder.
   - Merge all **nested subsections** into the parent section’s `.txt`.
   - Name files with numeric prefixes to preserve section order:  
     `01_Intro.txt`, `02_History.txt`, etc.
   - Tables should be saved as `.csv` files in the same folder, named `Table_1.csv`, `Table_2.csv`, etc.
   - Images should be saved as `.png` files in the same folder, named `Image_1.png`, `Image_2.png`, etc.

4. **File Naming Safety**
   - Slugify all folder and file names to avoid spaces, slashes, and special characters.

5. **Images**
   - Download **original-resolution** images, not thumbnails.

6. **Error Handling**
   - Skip missing sections, empty tables, or failed image downloads without stopping the program.

7. **Extra**
   - Add a `metadata.json` inside each article folder containing:
     - Article URL
     - Download timestamp
     - List of created files

8. **Performance**
   - Add a small delay (e.g., 1 second) between API calls to avoid rate-limiting.

## Output Example

Monkey_D_Luffy/
01_Intro.txt
02_History.txt
03_Abilities.txt
Table_1.csv
Table_2.csv
Image_1.png
Image_2.png
metadata.json
